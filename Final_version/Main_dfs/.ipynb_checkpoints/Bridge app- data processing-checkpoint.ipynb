{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping- data to `bridge app`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short description\n",
    "In our project we try to create app which enable to see statistics and progress of selected player. Additionally, we can follow rating of particular player and compare it to other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating data frame of played boards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first step we create data frame where we store data of played boards. Boards are from `KMP`tournament- taking place every month with about 500 pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get this data we can use `pandas` library, which enable easy web scrapping. Firstly we have to create some pipelines to structure data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist(vector,n=30):\n",
    "    pd.read_html(requests.get(f\"https://r.bridgespider.com/{vector[0]}/prot/{1}/\").content)[-1].to_csv(\"mydata.csv\")\n",
    "    tmp=pd.read_csv('mydata.csv')\n",
    "    tmp['nr_rozdania']=1\n",
    "    tmp['nr_turnieju']=vector[0]\n",
    "    for j in range (len(vector)):\n",
    "        for i in range(1,n):\n",
    "            if j>0:\n",
    "                i=i-1\n",
    "            pd.read_html(requests.get(f\"https://r.bridgespider.com/{vector[j]}/prot/{i+1}/\").content)[-1].to_csv(\"mydata.csv\")\n",
    "            zz=pd.read_csv('mydata.csv')\n",
    "            zz['nr_rozdania']=i+1\n",
    "            zz['nr_turnieju']=vector[j]\n",
    "            tmp=pd.concat([tmp,zz])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df2):\n",
    "    df2=df2.drop(['Unnamed: 0','ośrodek','runda','wist','Unnamed: 11','lew','kontrakt'],axis=1)\n",
    "    df2['rozg.']=df2['rozg.'].replace(['E','W'],'EW')\n",
    "    df2['rozg.']=df2['rozg.'].replace(['N','S'],'NS')\n",
    "    df2['zapis_NS']=df2['zapis']\n",
    "    df2['zapis_EW']=df2['zapis']*(-1)\n",
    "    df2=df2.drop('zapis',axis=1)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline2(df_x):\n",
    "    tmp1=df_x.copy()\n",
    "    tmp2=df_x.copy()\n",
    "    tmp1=tmp1.drop(['EW','% EW','zapis_EW'],axis=1)\n",
    "    tmp1['linia']='NS'\n",
    "    tmp2=tmp2.drop(['NS','% NS','zapis_NS'],axis=1)\n",
    "    tmp2['linia']='EW'\n",
    "    tmp1.columns=['id','rozg','wynik','nr_rozdania','nr_turnieju','zapis','linia']\n",
    "    tmp2.columns=['id','rozg','wynik','nr_rozdania','nr_turnieju','zapis','linia']\n",
    "    tmp=pd.concat([tmp1,tmp2])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refactor(history):\n",
    "    history=pipeline(history)\n",
    "    history=pipeline2(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 4 functions allow us to create our first data frame. Unfortunately, we have only id unique for particular tournament. Now we need data frame with names of these players. To get access to the data we have to use once again web scrapping tools. After this action we merge these 2 data frames and receive data set with almost unique id (name and surname)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data frame with scores and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_pipeline(url):\n",
    "    pd.read_html(requests.get(url).content)[-1].to_csv(\"mydata.csv\")\n",
    "    df=pd.read_csv('mydata.csv')\n",
    "    df=df.drop(['Unnamed: 0','+/-','pkl', 'pdf'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_trans_scores(df):\n",
    "    import re\n",
    "    pierwszy=[]\n",
    "    drugi=[]\n",
    "    for i in range(len(df)):\n",
    "        pierwszy.append(re.findall('[aA-ZŻŹĆĄŚĘŁÓŃ][^A-ZŻŹĆĄŚĘŁÓŃ]*', df.nazwiska[i])[0]+re.findall('[aA-ZŻŹĆĄŚĘŁÓŃ][^A-ZŻŹĆĄŚĘŁÓŃ]*', df.nazwiska[i])[1])\n",
    "        drugi.append(re.findall('[aA-ZŻŹĆĄŚĘŁÓŃ][^A-ZŻŹĆĄŚĘŁÓŃ]*', df.nazwiska[i])[2]+re.findall('[aA-ZŻŹĆĄŚĘŁÓŃ][^A-ZŻŹĆĄŚĘŁÓŃ]*', df.nazwiska[i])[3])\n",
    "    \n",
    "    df['nazwisko_1']=pierwszy\n",
    "    df['nazwisko_2']=drugi\n",
    "    df=df.drop('nazwiska',axis=1)\n",
    "\n",
    "\n",
    "    wk1=[]\n",
    "    wk2=[]\n",
    "    for i in range(len(df)):\n",
    "        wk1.append(re.findall(\"\\d+\\.\\d\", df.wk[i])[0])\n",
    "        wk2.append(re.findall(\"\\d+\\.\\d\", df.wk[i])[1])\n",
    "    df['wk_1']=wk1\n",
    "    df['wk_2']=wk2\n",
    "    df=df.drop(['wk','ośrodek','okręg'],axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline3(scores):\n",
    "    scores_1=scores[['m-ce', 'nr', '%', 'nazwisko_1','wk_1','nr_turnieju']]\n",
    "    scores_2=scores[['m-ce', 'nr', '%', 'nazwisko_2','wk_2','nr_turnieju']]\n",
    "    \n",
    "    scores_1['nazwisko']=scores_1['nazwisko_1']\n",
    "    scores_2['nazwisko']=scores_2['nazwisko_2']\n",
    "    \n",
    "    scores_1['wk']=scores_1['wk_1']\n",
    "    scores_2['wk']=scores_2['wk_2']\n",
    "    \n",
    "    scores_1=scores_1.drop(['nazwisko_1','wk_1'],axis=1)\n",
    "    scores_2=scores_2.drop(['nazwisko_2','wk_2'],axis=1)\n",
    "    \n",
    "    scores_new=pd.concat([scores_1,scores_2])\n",
    "    return scores_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge data frame history and scores on `name`. However, we have to remember that it can be possible that exist 2 players with the same name and surname. We can't manage with this fact because of not having unique id for every player. Our solution is to delete all players with same name and surname. It's a simplification but not so meningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Players data frame\n",
    "Now we download data frame with all players who played at least once in tournament. From this table we get `PID`- unique id. Then we can merge on this number instead of merging on name and surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_players_df():\n",
    "    url=\"https://msc.com.pl/cezar/?p=51&rok=0&page=1\"\n",
    "    pd.read_html(requests.get(url).content)[-1].to_csv(\"mydata.csv\")\n",
    "    df=pd.read_csv('mydata.csv')\n",
    "    tables = pd.read_html(url,match=\"klub / drużyna\")\n",
    "    df=tables[2]\n",
    "    for i in range(337):\n",
    "        url=f\"https://msc.com.pl/cezar/?p=51&rok=0&page={i}\"\n",
    "        tables = pd.read_html(url,match=\"klub / drużyna\")\n",
    "        df=pd.concat([df,tables[2]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merging_drop_duplicate_names(history,scores,df):\n",
    "    df.rename(columns = {1: 'PID'}, inplace = True)\n",
    "    df.rename(columns = {2: 'name'}, inplace = True)\n",
    "    \n",
    "    scores=scores.merge(df[['PID','name']],left_on='nazwisko',right_on='name')\n",
    "    scores=scores.drop(['name'],axis=1)\n",
    "    \n",
    "    duplicates=scores[scores[['nr_turnieju','nazwisko']].duplicated(keep=False)]\n",
    "    scores=pd.concat([scores,duplicates]).drop_duplicates(keep=False)\n",
    "    return scores,history.merge(scores, left_on=['id','nr_turnieju'],right_on=['nr','nr_turnieju'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Progress of player\n",
    "Other important feature of our app is possibilty to check progress of player. Progress means for us final results of all played tournaments. That's why we have to create one more data frame which contains `PID` of player and all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab=[25890,25845,25809,25773,25737,25692,24384,24339,24303,24267,24222,24186,24150,22079 ,22043 ,21800,21764,21728,17693,17666] # default tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def players_progres(history,tab):\n",
    "    tab.insert(len(tab),'PID')\n",
    "    vector=history['PID'].unique()\n",
    "    df_x=pd.DataFrame(index=np.arange(len(vector)), columns=np.arange(len(tab)))\n",
    "    df_x.columns=tab\n",
    "    k=0\n",
    "    for i in range(len(vector)):\n",
    "        tmp=history[history['PID']==vector[i]][['PID','%','nr_turnieju']].drop_duplicates()\n",
    "        df2=pd.DataFrame(index=np.arange(1), columns=np.arange(2))\n",
    "        for j in range(len(tab)-1):\n",
    "            df2.loc[j,0]=tab[j]\n",
    "\n",
    "        df2=df2.rename({0:'nr_turnieju'},axis=1)\n",
    "        df2=df2.merge(tmp,on='nr_turnieju',how='left')\n",
    "\n",
    "        vec=np.array([vector[i]])\n",
    "        vec2=df2['%'].to_numpy()\n",
    "        df_x.iloc[i,:]=np.concatenate((vec2,vec),axis=0)\n",
    "        k=k+1\n",
    "        \n",
    "    return df_x.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of particular players\n",
    "Our large data frame include now only scores from all played boards. We need some additional statistics like average result but with specification if player defends or declares. The solution is to separate boards to some categories and add number of columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate to declarers and defenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separating_def_dec(history):\n",
    "    declarers=history[history['rozg']==history['linia']]\n",
    "    defenders=history[history['rozg']!=history['linia']]\n",
    "    declarers['czy_rozgrywa']=True\n",
    "    defenders['czy_rozgrywa']=False\n",
    "    history=pd.concat([declarers,defenders])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate to kinds of contracts- (częściowka-partial, końcówka, slam or above)\n",
    "We also need here simplification because of not having access to details of boards. However, having number of points get by declarer (only positive number) we can almost surely predict kind of contract. Additionally, we create category for boards when declarer loses (`Wpadka`) and category for defenders when they achieve positive result (`Kokosy_na_Obronie`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separating_contracts(history):\n",
    "    tmp1=history[ (history['zapis']>0) & (history['czy_rozgrywa'] )]\n",
    "    tmp1['zapis2']=pd.cut(history['zapis'], bins=[0, 300, 900, math.inf],labels=['częściówka','końcówka','szlemik'], include_lowest=True)\n",
    "    tmp2=history[ (history['zapis']<0) & (history['czy_rozgrywa']==False )]\n",
    "    tmp2['zapis2']=pd.cut(history['zapis'], bins=[-math.inf,-900,-300,0],labels=['szlemik','końcówka','częściówka'], include_lowest=True)\n",
    "    tmp3=history[ (history['zapis']>=0) & (history['czy_rozgrywa']==False )]\n",
    "    tmp3['zapis2']='Kokosy_na_Obronie'\n",
    "    tmp4=history[ (history['zapis']<=0) & (history['czy_rozgrywa']==True )]\n",
    "    tmp4['zapis2']='Wpadka'\n",
    "    history=pd.concat([tmp1,tmp2,tmp3,tmp4])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have data frame with results of all boards from selected tournaments. Now we can create new data frame with statistics of particular player. But firstly we need some groupby statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_mean(history):\n",
    "    stats2=history[history['czy_rozgrywa']==True].groupby(['PID'])['wynik'].mean().reset_index(name='średnia_na_rozgrywce')\n",
    "    stats3=history[history['czy_rozgrywa']==False].groupby(['PID'])['wynik'].mean().reset_index(name='średnia_na_obronie')\n",
    "\n",
    "    stat=stats2.merge(stats3,on='PID',how=\"outer\")\n",
    "\n",
    "    stat4=history[history['zapis2']==\"Kokosy_na_Obronie\"].groupby(['PID'])['wynik'].mean().reset_index(name=\"Kokosy_na_Obronie\")\n",
    "    stat5=history[history['zapis2']==\"częściówka\"].groupby(['PID'])['wynik'].mean().reset_index(name=\"częściówka\")\n",
    "    stat6=history[history['zapis2']==\"końcówka\"].groupby(['PID'])['wynik'].mean().reset_index(name=\"końcówka\")\n",
    "    stat7=history[history['zapis2']==\"szlemik\"].groupby(['PID'])['wynik'].mean().reset_index(name=\"szlemik\")\n",
    "    stat8=history[history['zapis2']==\"Wpadka\"].groupby(['PID'])['wynik'].mean().reset_index(name=\"Wpadka\")\n",
    "\n",
    "\n",
    "    stat=stat.merge(stat4,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat5,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat6,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat7,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat8,on='PID',how=\"outer\")\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_count(history):\n",
    "    stats2=history[history['czy_rozgrywa']==True].groupby(['PID'])['wynik'].count().reset_index(name='liczba_rozdan_na_rozgrywce')\n",
    "    stats3=history[history['czy_rozgrywa']==False].groupby(['PID'])['wynik'].count().reset_index(name='liczba_rozdan_na_obronie')\n",
    "    stat4=history[history['zapis2']==\"Kokosy_na_Obronie\"].groupby(['PID'])['wynik'].count().reset_index(name=\"liczba_rozdan_Kokosy_na_Obronie\")\n",
    "    stat5=history[history['zapis2']==\"częściówka\"].groupby(['PID'])['wynik'].count().reset_index(name=\"liczba_rozdan_częściówka\")\n",
    "    stat6=history[history['zapis2']==\"końcówka\"].groupby(['PID'])['wynik'].count().reset_index(name=\"liczba_rozdan_końcówka\")\n",
    "    stat7=history[history['zapis2']==\"szlemik\"].groupby(['PID'])['wynik'].count().reset_index(name=\"liczba_rozdan_szlemik\")\n",
    "    stat8=history[history['zapis2']==\"Wpadka\"].groupby(['PID'])['wynik'].count().reset_index(name=\"liczba_rozdan_Wpadka\")\n",
    "    \n",
    "    stat=stats2.merge(stats3,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat4,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat5,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat6,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat7,on='PID',how=\"outer\")\n",
    "    stat=stat.merge(stat8,on='PID',how=\"outer\")\n",
    "    return stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve average scores using something like min-max scaler. In this way we compare players to each other. For example a lot of players have score of `Wpadka` equals about 30%. After using our scaler difference beetween players with 30% and 39% is not miserable 9 % but more meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_percentile(df_stats):\n",
    "    df_score_upd=pd.DataFrame({'PID':df_stats['PID']})\n",
    "    vector=['średnia_na_rozgrywce', 'średnia_na_obronie', 'Kokosy_na_Obronie', 'częściówka', 'końcówka', 'szlemik', 'Wpadka']\n",
    "    for i in vector:\n",
    "        vec=df_stats[i]\n",
    "        wektor=[]\n",
    "        for j in range(len(vec)):\n",
    "            wektor.append(round((vec[vec<vec[j]].count()/len(vec))*100,2))\n",
    "        df_score_upd[i]=wektor\n",
    "    return df_score_upd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we want to generate ranking of players according to `df_stats`. Which variable should be the most important one? In our opinion, the user should decide about that. So one of input argument allow user to select the ranking's feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ranking(feature,stats): \n",
    "    stats=stats[['PID','name',feature]]\n",
    "    return stats.sort_values(by=feature, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other idea for creating ranking:\n",
    "- we got number of tournament results let's say $n$. We can use a weighted average to prepare ranking. The weights would be counted in this way: \n",
    "    - last tournament weight=1, previous tournament $\\frac{n-1}{n}$, then $\\frac{n-2}{n}$ and so on. Last tournament's weight in ranking would be equals $\\frac{1}{n}$\n",
    "    - we divide (sum of results multipled by weights) by sum of weight\n",
    "    $$\\frac{\\sum_{j=1}^{n} W_{i}*X{i}}{\\sum_{j=1}^{n} W_{i}}   $$\n",
    "$W_{i}$ - weight of i-th tournament<br>\n",
    "$X_{i}$ - result of i-th tournament<br>\n",
    "$n$ - number of played tournaments\n",
    "- in our opinion is quite fair; players who played only one tournament for example one year ago even with good score don't take the high position\n",
    "- ranking informs us about progress as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_ranking_generator(players_progress,players):\n",
    "    df=pd.DataFrame()\n",
    "    df['PID']=players_progress['PID']\n",
    "    final=np.array([])\n",
    "    for j in range(len(players_progress)):\n",
    "        vec=players_progress.fillna(0).loc[j, :].values.tolist()[0:len(players_progress.columns)-1]\n",
    "        indexes=[z for z, x in enumerate(vec) if x !=0]    \n",
    "        weights=np.round(np.arange(1, 0, -1/(len(players_progress.columns)-1)).tolist(),2)\n",
    "        suma=0\n",
    "        for i in range(len(indexes)):\n",
    "            suma+=weights[indexes[i]]\n",
    "        score=np.sum(np.dot(vec,weights))/suma\n",
    "        if len(indexes)==1:\n",
    "            score=0.65*score\n",
    "        elif len(indexes)==2:\n",
    "            score=0.8*score\n",
    "        elif len(indexes)==3:\n",
    "            score=0.9*score\n",
    "        elif len(indexes)==4:\n",
    "            score=0.95*score\n",
    "        if np.median(indexes)>(len(players_progress.columns)-1)/2:\n",
    "            score=0.8*score\n",
    "        final=np.append(final,score)    \n",
    "    df['ranking']=(final/max(final))*100\n",
    "    df=df.sort_values(by='ranking',ascending=False)\n",
    "    df['ranking']=round(df['ranking'],2)\n",
    "    df['PID']= df['PID']. astype (int)\n",
    "    df['PID']= df['PID']. astype (str)\n",
    "    wektor=[]\n",
    "    for v in df['PID']:\n",
    "        wektor.append(v.rjust(5,'0'))\n",
    "    df['PID']=wektor\n",
    "    df=df.merge(players[['PID','name']],on='PID')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this part we have all data frames which we need. Short description:\n",
    "- `df`: data frames with all players from Polish Bridge Union (`PZBS`)\n",
    "- `history`: all boards played in selected tournaments\n",
    "- `scores`: final scores from particular tournament\n",
    "- `df_stats`: all numbers in cells tells us about percentile of selected player. For example result `50` means that this\n",
    "player has better result than 50% of all players. Next variables are number of boards played in particular category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we want to easy run this script. In the last part, we write final version of functions, which enable to get data frame which we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get final version of df (players names and id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=creating_players_df()  # you need a little bit of time to get results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get first version of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: tab_add is array with ids (except tournament with id 25890 it's set default) of tournaments which you want to select (you can get this number from URL).\n",
    "def first_score(tab_add,n=25890):\n",
    "    scores=scores_pipeline(\"https://r.bridgespider.com/25890/\")\n",
    "    scores=regex_trans_scores(scores)\n",
    "    scores['nr_turnieju']=n  #create instance for 1 tournament\n",
    "    scores=pipeline3(scores)\n",
    "    for v in range(len(tab_add)):\n",
    "        tmp=scores_pipeline(f\"https://r.bridgespider.com/{tab_add[v]}/\")\n",
    "        tmp['nr_turnieju']=tab_add[v]\n",
    "        tmp=regex_trans_scores(tmp)\n",
    "        tmp=pipeline3(tmp)\n",
    "        scores=pd.concat([scores,tmp])\n",
    "    scores=scores.drop_duplicates(subset = ['%', 'nazwisko'], keep = 'last').reset_index(drop = True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get final version of history and final version of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: tab_test- exactly like tab_add but you must add also `25890` tournament\n",
    "#        scores- output of `first_scores()`\n",
    "#        df- output of `creating_players_df()`\n",
    "def final_history_scores(tab_test,scores,df):\n",
    "    history=get_hist(tab_test)\n",
    "    history=refactor(history)\n",
    "    scores,history=merging_drop_duplicate_names(history,scores,df)\n",
    "    history=separating_def_dec(history)\n",
    "    history=separating_contracts(history)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get final version of df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: like above\n",
    "def final_stats(history,df):\n",
    "    \n",
    "    df_stats=stats_mean(history).merge(stats_count(history),on='PID')\n",
    "    df_stats_new=stats_percentile(df_stats)\n",
    "    df_stats_new=df_stats_new.merge(df[['PID','name']],on='PID')\n",
    "\n",
    "    df_stats_new=stats_percentile(df_stats)\n",
    "    df_stats_new=df_stats_new.merge(df_stats[['PID','liczba_rozdan_na_rozgrywce', 'liczba_rozdan_na_obronie',\n",
    "       'liczba_rozdan_Kokosy_na_Obronie', 'liczba_rozdan_częściówka',\n",
    "       'liczba_rozdan_końcówka', 'liczba_rozdan_szlemik',\n",
    "       'liczba_rozdan_Wpadka']],on='PID')\n",
    "    df_stats=df_stats_new.merge(df[['PID','name','8']],on='PID')\n",
    "    df_stats['PID']=df_stats['PID'].astype (str)\n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create stats to website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_to_web(history,df):\n",
    "    stats_to_website=final_stats(history,df)\n",
    "    stats_to_website=stats_to_website.rename(columns={'8':'klub'})\n",
    "    stats_to_website['klub']=stats_to_website['klub'].fillna(\"Brak klubu\")\n",
    "    stats_to_website=stats_to_website[['PID', 'średnia_na_rozgrywce', 'średnia_na_obronie',\n",
    "       'Kokosy_na_Obronie', 'częściówka', 'końcówka', 'szlemik', 'Wpadka','name', 'klub']]\n",
    "    return stats_to_website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing positions in rankings\n",
    "Our ranking should show also progress of player. We can count progress as difference between of position in last and recent ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ranking_with_difference(old_ranking,new_ranking,df):\n",
    "    old_ranking.reset_index(inplace=True)\n",
    "    new_ranking.reset_index(inplace=True)\n",
    "    \n",
    "    old_ranking=old_ranking.rename(columns={'index':'old_place'})\n",
    "    new_ranking=new_ranking.rename(columns={'index':'new_place'})\n",
    "    new_ranking['new_place']=new_ranking['new_place']+1\n",
    "    old_ranking['old_place']=old_ranking['old_place']+1\n",
    "    \n",
    "    \n",
    "    tmp=new_ranking.merge(old_ranking,on='PID',how='outer')\n",
    "    tmp=tmp.rename(columns={'ranking_y':'old_ranking','ranking_x':'new_ranking','name_x':'name'})\n",
    "    \n",
    "    tmp['difference']=tmp['old_place']-tmp['new_place']\n",
    "    tmp=tmp[['PID','name','new_ranking','difference','new_place']]\n",
    "    \n",
    "    \n",
    "    tmp=tmp.merge(df[['PID','name']],on='PID')\n",
    "    tmp=tmp.drop('name_x',axis=1)\n",
    "    tmp=tmp.rename(columns={'name_y':'name'})\n",
    "    tmp=tmp.fillna(0)\n",
    "    \n",
    "    tmp['difference']=tmp['difference'].astype(np.int)\n",
    "    tmp['difference']=tmp['difference'].astype(np.str)\n",
    "    \n",
    "    tmp=tmp.sort_values(by='new_ranking',ascending=False)\n",
    "    \n",
    "    for i in range (len(tmp['difference'])):\n",
    "        if int(tmp['difference'][i])>0:\n",
    "            tmp['difference'][i]=\"+\"+tmp['difference'][i]\n",
    "       \n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_zeros(df):\n",
    "    wektor=[]\n",
    "    for v in df['PID']:\n",
    "        wektor.append(v.rjust(5,'0'))\n",
    "    df['PID']=wektor\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_from_csv():\n",
    "    df=pd.read_csv(\"df.csv\",index_col=False)\n",
    "    history=pd.read_csv(\"history.csv\",index_col=False)\n",
    "    stats=pd.read_csv(\"stats.csv\",index_col=False)\n",
    "    scores=pd.read_csv(\"scores.csv\",index_col=False)\n",
    "    players_progress=pd.read_csv(\"players_progress.csv\",index_col=False)\n",
    "    new_ranking=pd.read_csv(\"new_ranking.csv\",index_col=False)\n",
    "    \n",
    "    df['PID']=df['PID'].astype(str)\n",
    "    df=five_zeros(df)\n",
    "    \n",
    "    history['PID']=history['PID'].astype(str)\n",
    "    history=five_zeros(history)\n",
    "    \n",
    "    stats['PID']=stats['PID'].astype(str)\n",
    "    stats=five_zeros(stats)\n",
    "    \n",
    "    \n",
    "    players_progress['PID']=players_progress['PID'].astype(str)\n",
    "    players_progress=five_zeros(players_progress)\n",
    "    \n",
    "    new_ranking['PID']=new_ranking['PID'].astype(str)\n",
    "    new_ranking=five_zeros(new_ranking)\n",
    "    \n",
    "    return df,history,stats,scores,players_progress,new_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DB_connection():\n",
    "    import pymysql\n",
    "    import csv\n",
    "    connection = pymysql.connect(host=\"localhost\",user=\"root\",passwd=\"\",database=\"tests\" )\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute('DROP TABLE IF EXISTS final_ranking')\n",
    "\n",
    "    sql=\"CREATE TABLE final_ranking(PID int, Ranking varchar(32), `Zmiana pozycji` varchar(32), Miejsce int, Zawodnik varchar(32))\"\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    csv_data = csv.reader(open('final_ranking.csv',encoding=\"utf-8\"))\n",
    "    next(csv_data)\n",
    "    for row in csv_data:\n",
    "        cursor.execute('INSERT INTO final_ranking(PID, Ranking, `Zmiana pozycji` , Miejsce, Zawodnik) VALUES(%s, %s, %s, %s, %s)',row)\n",
    "    \n",
    "    # DB second table\n",
    "    cursor.execute('DROP TABLE IF EXISTS table_2')\n",
    "\n",
    "    sql=\"CREATE TABLE table_2(PID int, średnia_na_rozgrywce float, średnia_na_obronie float, Kokosy_na_Obronie float, częściówka float, końcówka float, szlemik float, Wpadka float, name varchar(32), klub varchar(32))\" \n",
    "\n",
    "    cursor.execute(sql)\n",
    "\n",
    "    csv_data = csv.reader(open('stats.csv',encoding=\"utf-8\"))\n",
    "    next(csv_data)\n",
    "    for row in csv_data:\n",
    "        cursor.execute('INSERT INTO table_2(PID, średnia_na_rozgrywce, średnia_na_obronie, Kokosy_na_Obronie, częściówka, końcówka, szlemik, Wpadka, name, klub) VALUES(%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)',row)\n",
    "\n",
    "    connection.commit()\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we don't have 2 rankings to compare. We solved this problem creating 2 rankings: for 10 and 20 tournaments. In this way, we created first version of website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_test=[25890,25845,25809,25773,25737,25692,24384,24339,24303,24267,24222,24186,24150,22079 ,22043 ,21800,21764,21728,17693,17666]\n",
    "compar_tab=[24222,24186,24150,22079 ,22043 ,21800,21764,21728,17693,17666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,history,stats,scores,players_progress,new_ranking=get_from_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_to_website=stats_to_web(history_20,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_10=pd.read_csv(\"history_10.csv\",index_col=False)\n",
    "history_20=pd.read_csv(\"history_20.csv\",index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_20.to_csv(\"history.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_progress_10=players_progres(history_10,compar_tab)\n",
    "players_progress_20=players_progres(history_20,tab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranking_10=new_ranking_generator(players_progress_10,df)\n",
    "new_ranking_20=new_ranking_generator(players_progress_20,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranking_10.to_csv(\"new_ranking_10.csv\",index=False)\n",
    "new_ranking_20.to_csv(\"new_ranking_20.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ranking_20.to_csv(\"new_ranking.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranking=generate_ranking_with_difference(new_ranking_10,new_ranking_20,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In every next loading, we compare last position of player with position in new ranking (old ranking + this month's tourament)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df(n):\n",
    "    df,history,stats,scores,players_progress_old,old_ranking=get_from_csv()\n",
    "    \n",
    "    tabb=pd.read_csv(\"zzz.csv\",index_col=False)\n",
    "    tabbb=tabb['0']\n",
    "    tab_test_new=np.array(tabbb)\n",
    "    tab_test_new=np.append(n,tab_test_new)\n",
    "    \n",
    "    history_1=final_history_scores([n],first_score([n]),df)\n",
    "    history_new=pd.concat([history_1,history])\n",
    "    \n",
    "    stats_to_website=stats_to_web(history_new,df)\n",
    "\n",
    "    score_1=first_score([n])\n",
    "    score_1=score_1[score_1['nr_turnieju']!=25890]\n",
    "    scores_new=pd.concat([scores,score_1])\n",
    "    \n",
    "    players_progress_new=players_progres(history_new,tab_test_new.tolist())\n",
    "    new_ranking=new_ranking_generator(players_progress_new,df)\n",
    "    final_ranking=generate_ranking_with_difference(old_ranking,new_ranking,df)\n",
    "\n",
    "    players_progress_new.to_csv(\"players_progress.csv\",index=False)\n",
    "    new_ranking.to_csv(\"new_ranking.csv\",index=False)\n",
    "    history_new.to_csv(\"history.csv\",index=False)\n",
    "    stats_to_website.to_csv(\"stats.csv\",index=False)\n",
    "    scores_new.to_csv(\"scores.csv\",index=False)\n",
    "    final_ranking.to_csv(\"final_ranking.csv\",index=False)\n",
    "    pd.DataFrame(tab_test_new).to_csv(\"zzz.csv\",index=False)\n",
    "    \n",
    "    DB_connection()\n",
    "   \n",
    "    \n",
    "    return final_ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating directory with json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_content(path):\n",
    "    import os, shutil\n",
    "    folder = path\n",
    "    for filename in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_progress(data):\n",
    "    delete_content('C:\\\\xampp\\\\htdocs\\\\test\\\\results')\n",
    "    players_progress=pd.read_csv(\"players_progress.csv\",index_col=False)\n",
    "    \n",
    "    players_progress=pd.concat([players_progress.iloc[:,0:20],players_progress['PID']],axis=1)\n",
    "    \n",
    "    zz=pd.read_csv('dupxo.csv')['0']\n",
    "    zz=zz.tolist()\n",
    "    zz=zz[0:19]\n",
    "    zz.insert(0,data)\n",
    "    zz.append('PID')\n",
    "    players_progress.columns=zz\n",
    "    \n",
    "    dupxo2=[0]*len(zz)\n",
    "    for i in range( len(zz)-1):\n",
    "        dupxo2[i]=zz[len(zz)-2-i]\n",
    "    dupxo2[len(zz)-1]='PID'    \n",
    "    \n",
    "    players_progress=players_progress[dupxo2]\n",
    "    \n",
    "    for i in range(len(players_progress)):\n",
    "        k=players_progress.loc[i,:]['PID'].astype(int)\n",
    "        players_progress.iloc[i,0:len(players_progress.loc[0,:])-1].to_json(f'C:\\\\xampp\\\\htdocs\\\\test\\\\results\\\\{k}.json')\n",
    "    zz.pop()\n",
    "    pd.DataFrame(zz).to_csv('dupxo.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_progress(\"08.2022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to update results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After every tournament we have to update ranking and stats of all players. Unfortunatelly, this process isn't automatic, because of quiet random choice of tournament number in URL. However, if we want to update our page, we have to run only 2 functions:\n",
    "- `update_df(n)`- where `n` is number of last tournament(we can find it in URL)\n",
    "- `json_progress(date)`- where `date` is date of last tournament in format MM.YYYY\n",
    "\n",
    "After running these 2 functions we can refresh our website and see updated ranking and stats.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
